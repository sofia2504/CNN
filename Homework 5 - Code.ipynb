{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1"
      ],
      "metadata": {
        "id": "qZh6c3MR148R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AWkRlptt1Zp4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Verify dataset loading\n",
        "batch = next(iter(trainloader))\n",
        "print(batch[0].shape, batch[1].shape)\n",
        "\n",
        "# Visualize images\n",
        "f, ax = plt.subplots(2, 5)\n",
        "plt.subplots_adjust(bottom=0.3, top=0.7, hspace=0)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(5):\n",
        "        image, label = next(iter(trainloader))\n",
        "        ax[i][j].set_axis_off()\n",
        "        ax[i][j].imshow(image[0,0,:], cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "Ok3sUizD1pkR",
        "outputId": "79ed68d3-a2bd-40d6-b827-22eea28562fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:04<00:00, 6.52MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 140kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 2.55MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.57MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAADJCAYAAABc6yrVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwk0lEQVR4nO2dZ5RV5RWGP2PX2EAUsSEgAgoKgwgoikEgolgWxoYGly4lxhqWMZKYJioaUdQoGkuM2BIJAkqUhcGCCEpzaAJSLCCICoi9m1/sPOdbZ985d+bemXuH9/n1ejn9nO/M8d3f3nuzH3744YcghBBCiE2aH9X1AQghhBCi7tEHgRBCCCH0QSCEEEIIfRAIIYQQIuiDQAghhBBBHwRCCCGECPogEEIIIUTQB4EQQgghQghbZF1ws802K+ZxbLIUoi6U7k1xqOm90X0pDuU+ZkaPHm167733Nr311lub/vLLL00vWrTIdM+ePU0vW7bM9FZbbWW6TZs2phs1apS6zWKhMVOaZL0vcgiEEEIIoQ8CIYQQQuQRMhBCCFFzunXrZvrDDz80ve2225rebbfdTH/xxRepeocddjD90Ucfmf7ggw9M77jjjqZrI2RQijRp0iTx33fffbfpefPmmf79739v+vvvvy/IvocPH266Xbt2pp988knTt912W0H2VQjkEAghhBBCHwRCCCGECGGzrO2PNfuzOJT7jOn6jGZMlyblOGaaNWtm+tVXXzX93nvvmd55551T133nnXdSl/nuu+9Mf/7556YZerjhhhtMP/bYY/kddDUo1pj50Y/+//+utPOZXXHppZeavvjii91j2mabbUx/9dVXqftbsGCBaYZv5s6dm7pur169TDdt2tT06tWrTTPcw3V5H+fMmZM4jssuu8w0w0L5oiwDIYQQQmRGHwRCCCGEKF6WgWfx1HSdiooK05xlu2TJEtO0zE455RTTtGOeeeaZ1O3TsqqO/VXT9YWoLbxn1bNtsyzjbT/X/jjWDznkENO77LKL6eeff77K/ZUyPXr0ML1u3TrTb775pun99tvP9O677256r732Ms3QwBZb/P/1/cknn5j+8Y9/bJoZDbURMigk3t8DPhejRo1KXZ72PMMKIYTw8ccfm2YxqKVLl5qeMmWK6XPPPdd0165dTdP25zafe+4503vssYfpb775xvTMmTNNM8RwwgknJI61e/fupgcOHGh6woQJoRjIIRBCCCGEPgiEEEIIUcSQgWf557Ias4QW2rdvb3rAgAGmPVtt1qxZpr/99lvTXsigpja/wgSiXPBCAFme4UItE3PwwQeb5mzwcg8Z9O7d2/SWW25pevvtt09dnjPKP/30U9MMB9CC/vrrr03zPbpixYrqHXAdsfnmm5vm7PuddtrJ9MSJE03zGeO5sjhT69atE/tgpgbXZ7iKPSbeeOMN07vuuqtp/j2hZuiH4Q1mlzDcvWrVKtPsTxFCCPvss4/pW2+91TT/DnrhET4TWZFDIIQQQgh9EAghhBCiDnoZZLUR9913X9PXXnutaVo59913n+knnnjCNG21/v37m77yyitNM/vgxhtvND1mzJhMxydEuZMlTHD77beb5ozp5cuXm548ebLpDRs2mKbVHUJyXNJ6pa3atm1b01dffXXuEygjeI60eBneJLT9vTCrF1agVVwd27guYaYAQwaDBw82zSJPtPNplzMbjcWE4uVatWplmmGGd9991zSzABjG4nb4O+/LmjVrTDNz5NBDDzX92WefmWYGSvzfHDPsx8DQeU3vtxwCIYQQQuiDQAghhBB13P54zz33TPw3bZCePXuanj9/vmlaY/fcc49pFnCgNcmCIMw4oMVz//33m77ppptMM6xQWVnpn4gQZQgL23DGOmfEH3DAAaY7d+5sevHixaZZrKVRo0am2Xo3hOTMau6PM7THjh1r2rPTyxHayyyG07x5c9OcSc+QAUM1vCa8blyeFjTbK5cDPCfitXFmxgaX4TWLCxPx+jBEwWea143ZB7z+XIYhIe6PWRMsmLd27VrT7JXAjIMQklko3DfDBx48t6zIIRBCCCGEPgiEEEIIUQchg4YNG5p+5ZVXEv/GWZ7Tp083zZmTnHVJG58tQrk8sxVo03Dm6IwZM0zTdpo0aZJp2kYhlF/Bj5pC+4kz0vOtb+/NZm/QoIFpWmiLFi3K6zhD8I81y3FsStC2J8cdd5xp2vyceb1y5UrTDP3R4oyvMWdfU3M2ObMU6hMMDfA9xOtA+5sW9JNPPmmaoVFeK9roLLxTbmEXb1wy+4R/A3j9mFnAa8M+AyEkw84M05Cjjz7aNHsW8Nry78ZBBx1kervttjPNUA5bXTNcx/A1Q24hJMMPPCc+HwyPsN1ydd5xcgiEEEIIoQ8CIYQQQuiDQAghhBChDuYQ/Otf/zIdV5AiTM1hmghjKoyjcHn2BucyjNu89dZbpjmvgfEiNpoYMWJE4vj69u3rHnt9JN9mVV78is067r33XtOs3sb5GqeffrrpeM5JVccQQjI+x33w/nXp0sX0b3/7W3db9QGvxzxjqRwPTOElrFTItEPOIYgrFXJ/jLNyzNWnuR2NGzc2zfQzvs+YisY5BLwmN9xwg2lWXl2/fr1pzhVgHNqbJ1JusOIfz7tNmzamea58juI5BF6DKM4f4zVkNUTOWSBMWWR6LtMoOa44Tjg3h89DCMk5C5xrw+PgMzFs2DDTmkMghBBCiGqhDwIhhBBC1E7I4JxzzjHdokUL00zbCCFpmdFqob3CcABtE68ZCG0WhhuYTsWKU7RoCG3REEL4+c9/bnrkyJGp69QneE29Cncexx57rGk2qqJVRguaFt20adNMP/DAA6bPPfdc07E1xv9mmIDhg+uvv940w0f1HS/0Q7uUTVj4O61X9nxnmijvKW3yEJLjj5Y44Xgtd/iuo81N+5shTaZvTpgwwfSCBQtMcxx6FQmZludd53KA1jvTNhkepv3Pc+VzG4cUuT5DaGycx/cGl58yZYpppnpyzCxcuNA07wWrfjI1nu+luAIh/w7yXctxfOaZZ5pmyKA6yCEQQgghhD4IhBBCCFHEkAFtkD/84Q+m582bl7pMCMmZx7QOaVXS4onX3wjtFK+SHjXDBJ7tRNsuhOQ5PfTQQ6n7q0/wvLwwAat7sfHUyy+/bPrpp582Tav+wAMPNM3ZuLfccovpI444wvTSpUtNDx8+PHEc48ePN01LdsiQIaY5Kzu2tusbfNa95/Nvf/ubadqlDK2NGzfONCvmec9D3FTGgyGorOuUA7x2rKTKdxvtaF6HwYMHV7l92sl8nrl9brPc6NSpk2mGUxge4d8Ghpy9RkIhhPDmm2+apkXfrFmz1O2yqi3HDysH8m8O9/3222+b5rPNY+U2GX6Lt8vlmBXEv5sMocRZPlmQQyCEEEIIfRAIIYQQopohg3wtSFortPzjGcW0wDgLk/YKZ3Z6fa15fNwm98flaZESr4BICEkbipb15ZdfnrqtLNesuuS7bS90wmvi9SUPIWlRjRo1ynSTJk1M//3vfzfN0A4trT59+pim7eyFcyZOnGiadmzPnj0Tx+c156GtytAQm4N4YahywHsOvNn9AwcONL3XXnuZZiYPm05xm5yRzWeFFngMl6MVynFJe7bc4bPH2eYMUTGkxXDq/PnzU7fpWchsnMN3Zzk3i2IRMz63fFfwXeS99+Nnsn379qZ53ZjNxqynJUuWmGZ2DcMYfIZp5zMkwXs6e/Zs00cddVTqdkJIvpOp+QwxLMR34ZgxY0K+yCEQQgghhD4IhBBCCJFHyMCzmWlbtWvXzjRnhL/++uumacuwWEcISZuHYQJaJd5MUlpKtH35u3fctFxoyeWyzWk/n3322ab/8pe/mF61alXq/gpNlkwKWkyedesVrQkheT9vvvlm0zNnzjT9wgsvmGb4gJYdZ/LyuntZJbzOHTp0SD3W2GajVUsYfuD6rVu3Ns2+BuVAlnHJMcDrzwyO0aNHm2YGwfTp003TwvXscI7V+JnncXgFcw4++ODU38sRZil5fSP4rho6dGiV22TIlNY5Z5Tzuq9cuTKPIy4tTjjhhNTfWZCOIS2PXIXL4lDwRtgj4bHHHkvdH/sd8PpzHDJjioWWFi1aZJrvH4apQ0i+t3msfOfxOTjjjDNMK2QghBBCiGqhDwIhhBBCVC/LwLOWr7vuOtNsB8kwgWfzx9vlTFlay7RQuDytNC5Pu5r7pm1Em5NwmbjHAeuRcxYqCxb94he/SN1uMeExU2dpX8yZ5rfeemtiObZyZdEhzgrff//9TTMLg3XIeW8Y/qG9ypnXXstc3o/YEmSYgc8F7VMexwcffGA67llR6mTJMGGo5bnnnjPNMEHLli1Nsy77/fffb5r9I3hdvZnv8TPnFcmh/Unr1eujUC7wvJhdQ81sjeeffz6vbXpjmhZyuYUM+E7ge4OhSRYmYn8Ar99K/HeGIVPa/l7PAu5vxYoVpplxwHcT+3mw+FpFRYVpjjFmgsRhar4LmQ3H8+OYO/TQQ0NNkEMghBBCCH0QCCGEECKPkIFnR9JqZAEU2vAs8kCrg4UdQkhaPrT3aaN4RY4I98FlvJnNXJ52Hi25uC40ZwqzkAtb/dY1nBVOa5L1snm+LNjx6quvJrbFlsQMAbFN66mnnmp63333NU3rl5oWGO8N7wefA8+6Y3gphGS4gsfBmfGczctz43UqRWLb3cuEufjii03/6U9/Mv3444+b5jU47LDDTHN2Mm1RZo4wg4bPA+9p/M6gJcvZ9Rw/vN8nnniiafYLKRdYlIbnzpnqc+fONZ2lDTefdV5fbp/ZW/HYKHWY5TNp0iTT7AXBMe2dH3vPdOzYMfFvfHfw2fvvf/9rms89eyrwuefyzCZgyJKhAY4NhibZW4HZDSEkMyoYLuL7ksswlMowRlbkEAghhBBCHwRCCCGEKED7Y9bup53JUALrK19zzTWm4yIkLNbgZQfwd69VqtcvgSEA2se0X2i38fgGDRqU2MdBBx1kul+/fqbff/990yeddJLpsWPHph5rIeC5XH/99abZepPWGG02Ws60/2MrjrNxeb1oI3MmMG06zhzm/hiu4Dl494yZDtwmwzchJK05rxY416emJVgsmCnjhb0YPvPuV8ztt99ums/khRdeaLpFixamr7rqKtMMEyxcuND0r3/9a9OrV682zWvm2bbx+PTsT6+AFgt+lWPIgO8C2vu8dnPmzMlrmxx7HBsM2/A9Wm6cd955phny9Fr5sg06/zY8/PDDpkeMGJFYx7PY+Tvf73yfMAxE+P6aOnWqaZ4DQ3QMl7Nw3x133JHYLscuz5UwnMK/lSeffHLq8rmQQyCEEEIIfRAIIYQQopohA85e5Kxs2p8vv/xy6rq0VmgZh5C0pWmreQWIvLbFhBaK1yqTx8GwB2cDx7b0kCFDTF955ZWmadexFncxQwZs38sCLnFd7I3wXHgdOCM2rvHt2f600HgduTzvK+8B7yuLA9G64/WkbUhrP27xylm+zDig5rXxwilnnXVWKBS8zrTL4z4MVRG3Z77ssstSl6P1ytAVW62yoNZrr71mmgW1vIwPrwcG3wHcfgjJZ5MFcxjG4O+0W5mdUi5UVlaa5ruA9v6MGTPy2iafF94bXh8WhSs3+IwwRMVwId9TDDFNmzbNNDMUYphlwOwAvu+5bxZ64vPNdxkL1TFcyrAZ3y1su8zzeeKJJxLHeu2115pmlhXfqSwox4yF6owZOQRCCCGE0AeBEEIIIaoZMujdu7dpztKknT9w4MDUdWnPxrW4OZOYM4w9m4b75jLerGdaP7SauE3aTm3btjXttckMIdn2l7NHGU7JUnO+unD26e9+9zvTPEfaR7TGvNn6cVEL/jevNa8pz4thBdppDAfQ9s/VerkYcEYyQx20EAsJrw2vP+1FXmNapGwr3qNHD3cfrIXPbBNay7SrGWribGZeA1qQcT+PjfAZ4nPOOvMhJGfIMwNm2bJlpmmFMjziZWOUMry+vEYMfbEgVBb4buM7iWOdRXnKjUsuuaTKZfgMs9AWZ9vzeaHVHkLyXnghO1r6zJjj8+1lkTDzisuwQB/DnL169TIdh3sY/mRfg6effto0sxoeffRR03w3x5kWHuU3yoQQQghRcPRBIIQQQoiahwxot/7nP/8xHc/83ohn+YeQtEuYjUDLmZaNV6SFvzMTgXYbj4MzzlnDn0VZaP/FMOPgrrvuMs3wwSmnnGJ61KhR7raqA2eZ0irjPaD1xGvCa5Wr6E1N8Cxr9lTgMtScpct7Tx2HG7yZ2FyH8LyLZU0zNPDHP/7RNOvX0+JjWIGhgHgWMjNcunXrZpohET7rXkYF7wvHG217ZgB4fUd4/eLCRLS1f/azn5lmpgptX14bhprKBd5PziRn6MQrdOPh1afn9plNUx/h+/q4445LXYa9AhjKDsF/pzBMxzAsCwe1atXKNMcDW7/z+DiuOCazPs9eWJzPViGRQyCEEEIIfRAIIYQQopohA84Epi195513Vr1DWLhxfWpa7LQqaet4xYg4c5R2itcKmbNCaWXSXso683369OmmaXOyHnafPn1MFzpkQPuJNjyzBmgp0iKP2+luJC6A44UWsljsntXPe+DZ/IT3ifc7PgavTr53rLzPDK3UFFqTw4YNM81ryxnQL774omkWRmG710svvTSxD4bsOIvZC3FxeWoeq1cUjPfdy9jh+IyvpWd5cszwmWA77jPOOCPtdEoavhuZ5eOdYxb47mV4hZRjeGUj3vvBC/15fU9y2essfsT7wuebGTLM2hg9erRpFtRi2JZF1hj65u881nfffdd0rvbmXkYE3ye8ZgxNZUUOgRBCCCH0QSCEEEKIPEIGLFZCe2Ty5MmmOYOZs2FpHXJmc1xAiLNjvRbGtDa9FsZea1taTTwmzuimhUv7hRZuLubNm2ea7ZPjvg2FhBYYtWere+ES6nhGvhd6ofba+nJ/WWx7bof33suCiEM73v74vHlhpUKGDNiOmM8tj5e9BRhW4vjhLP74GnDmMp9dWve8lxwzPCYuzxnW1Aw7MRzFZ47HEx+r90zw+vM4aH0Xq2BUbdGsWTPTb7zxhmkWm8kCQ5p8LhgqLGe8om3e2PfeJ3zfxlkX3MdLL71kmgXA2rRpY5r9VPbbbz/Thx56qGn+7eP2GRbnvevUqZNpZiXEmXcc0xwnvB5xFkVNkEMghBBCCH0QCCGEECKPkAHtZ1pV48aNS13es37mz59vesCAAYl/oy1Iu5D2LmeFchYv7RSvVS/hMoSWDWd/eq2EY/7973+bPu2000yzvnVt1WUvVvEKkQ2v3TZtQD7DnC1MO98rMhRC8jnm+t6MZIa+aHNSc4wdf/zxphnqYK13r3dIPMY4Rr2wFbfFWdnlWGyHdex5P6mZYcH3qpdNxfvP68nQQ75hiHLG+zvD1tnMzAgh+Xzz+tN65+8VFRWm+azyb4I39hjKZnEyjiX+bWDYMIQQRo4cmbpOsZBDIIQQQgh9EAghhBBCHwRCCCGECHnMIejSpYtpxkimTJmSuryXCsH+1YMGDUr821VXXWWaMVc2lGCMkfF+b04A40WMv3FuAeO4rATHJi8rVqxI3X4IybgS50gwBZF9zzt06OBuS9QfxowZY/r88883zRQ0zvPgM8l4IWOVuaqP8TnknACmGhKOJaYSEzbruuWWW0wzRvuPf/wjdb+5Kkjy/HgcXopx3CipHGAlQb4PeZ/Y/IapaKxaSfhe5NwSr9JkfcdLT2e8Pp53w3vRvHlz014FUcb4vUq2HMfefeF9Z2MkznFgU6YQknMIagM5BEIIIYTQB4EQQggh8ggZ0CpZuHCh6euvv940m/yMHTu2yu0wtSOEZPUz2ojsGc6qaFzeS7VhKk/Tpk1N0x5iaMCrEOeFRkLwU7xoO9G2jRsHifoJQwbUtDOZekvLuHXr1qb5HHqNn0JIpunRhmT1xXXr1plmmIChrrZt27r72AjH7uLFi02zKQzTdkMI4YgjjjDNdLFly5aZ5vuBzcFynXc5wOvFKnoMATC8mQVa07Svy7m5Ub54qXh818cpnHyWuP769etNe428+O7muPKqtDIk9Pbbb6ceK0OCuUJjSjsUQgghRK2gDwIhhBBCZA8ZLFmyxPSDDz5omrMiaZFn4dFHH038N63RVatWpf5Oa4aVDdmkgsvPmTPHNO1I2joMPXCb1Fmr/l1++eWpv19zzTWm2fBCbHrMnDkzVXvQ/oyzARgaYDiNvdr5+6xZs0wzS4fhPuI1JKI+9thjTbds2dJ0bJE2btzYNC1Zr3c9rV3Oyr7vvvtSj7WUYZi1e/fupnkdr7zyStNPPfVUtfdVyGY3pY5XqZD2OsNkIfhNgvgc7rHHHqYZRvaagDETjplAzGBj9gf/jvH4vIyg2kIOgRBCCCH0QSCEEEKIEDb7wfNc4gUxG5bQBsm3mU5cMIIzLLPMlM2yb4YPeA7cN7MYGD6g5clmLrngOXTu3Nk0LUPOBs94+XPi3RtRM2p6b3RfikM5jpl+/fqZfuCBB0zTLmbWAC1rQsuaIVra4O3btzed9b1VKGpjzHiWPzMAFixYYJpZHSEk/7bwOnuFsHjNGVaorKw0zb8/hx9+uGmvQBgzcBhCZkOsEEI45phjTHvhjSzZB1nvixwCIYQQQuiDQAghhBAFCBmImlGO9uemgkIGpUm5jxkWKaI1TfvaOz6eO+1o2smc8R5b0MWmNsZMFrv8yCOPNM0iXyGE0KNHD9M8XhbnYkYMM3u8fiPMJth9991NL1++3PTatWtTf2eGD7cfL0d4nbJcc4UMhBBCCJEZfRAIIYQQQiGDuqbc7c/6jEIGpUm5j5mJEyea5gx4trq9++67U9dlPwgWpaKNPnr06IIcZ3XQmClNFDIQQgghRGb0QSCEEEKI7CEDIYQQQtRf5BAIIYQQQh8EQgghhNAHgRBCCCGCPgiEEEIIEfRBIIQQQoigDwIhhBBCBH0QCCGEECLog0AIIYQQQR8EQgghhAghbJF1QTWdKA7l0qhlhx12MH3ppZeanjVrlukJEyYUZF/sV87e7nfeeWdBtp8VNWopTcplzNSE008/3fQuu+ximk2MvPHAc6vtQrQaM6WJmhsJIYQQIjP6IBBCCCFE9uZGsnKKQ6nan+zTHkIIlZWVpmlhfv7556bvvfde00OHDjX9zTffpO6jYcOGphmGGDhwoOnNN988dV+nnnqq6VdffTX9JGqI7M/SpFTHTE257rrrTK9evdr0HXfcYbpz586mL7nkEtP9+/dP3WZthw80ZkoThQyEEEIIkRl9EAghhBBCIYO6plTtzyeeeCLx30cffbTp999/3/RWW21lukGDBqZ33HFH019//bVpHusHH3xgmiGKjz/+2PQXX3yRus358+ebPuaYY3KdSrWR/VmalOqYyQVDX999953p448/3nT37t1NX3HFFVVuk9k4Xbt2NT1kyBDTW265pWkvdFdIym3MMGvj+++/r3J5Zn/suuuuprfY4v8Je7wGr732munJkyenbrM2wjoKGQghhBAiM/ogEEIIIUT2wkSi/nP55Zeb7tOnT+Lf3nvvPdPbbrutadpsDCWsXbvWNO00Qgvzs88+M7311lubpuW5fv160x07djTN2dYhhPDXv/41dX9C1BWeZcvCW8OGDUtdhpYy9aRJk0y3bds2dV2OsbosWFSq8N3E0CZ56qmnTC9ZssT0oEGDUpfn++vss882ffjhh5tmFhbvRRwyqe37JIdACCGEEPogEEIIIYRCBgI8/PDDprt165b4tw4dOpjmjOlvv/029XeGErwsA87wpeY2aZk1btzY9EMPPWRaIQJRiniZBU2bNjXNmeoMy3mz7RlC++qrr0zT+u7Zs6fpZ599NvV4OMY2ZbzMiwEDBpiePn26aWZwePC+3HfffaYvuOAC0yeffLLpMWPGmFbIQAghhBB1jj4IhBBCCKGQgfg/H374oel+/fol/u22224zfc4555hm4SDP3vLsT4YVuC4tt9122830M888YzrOLBCi1PBCBn379jXN4lyEM9U5HjxWrlxpulOnTqYZMmBYYVMKGeQqduS9syoqKkyzz0q+++P277nnHtODBw9OXTdLcaRiIodACCGEEPogEEIIIYRCBiIjRx11lGn2FGAxItpjzBrIVXhjI5ztS6uVs7DPPPPM1HW5rxDq3nYTIgS/0A0zdtgynHiZNp7VP3HiRNPDhw9PXSZL6KHciMd+GnFYwLP02a/Fyz7wwkDeMXlh0Xfeecd08+bNTS9btizTtrz3K6lOhoIcAiGEEELog0AIIYQQJRwy8Op3e3awN4OWbXUvuugi07TzKisrTbMIBevrV4cDDzzQNOuUH3vssTXabl3Amcs333yzaWYjsNfANttsY5rWlRc+oEXXsGFD0wMHDqzy2BQiKE1qWmTlxhtvND1y5MiCHFMxyRW62mGHHUxzbEydOjV1W54d7T3r69atM+2FBkqpZr5Hvv0WqjP2ve3uvvvuph999NHUZbz7ku8yDA00atQo9fcQ/PMr1jtPDoEQQggh9EEghBBCCH0QCCGEECKU8BwCL+5MGG/y0nEYg2aMiA1GTjnlFNNbbbWVaVbJO+OMMxLb9WJ/ZMGCBaa//PLLKpcvZTjngr28mQropQBlSYvhHBDG4MaNG5e6rnq71xxv3s22225r+p///Kfpxx9/3PQjjzxS5farc186duyYuj7HUl3jPXt8d4SQHPM//elPTXvnwsZFXtqbNw+Av69du9Y0Uxxnz56dum7W7dYGWfbH9wzf0bxmfLZz7YPzxPbaay/TS5cuNc1UQ6Zc835liemzEizHWIMGDdx1dtppJ9Mco15aKq+B0g6FEEIIUS30QSCEEEKI0goZeFXsvAp43jJdu3Y1vffee6cuw0pR1LvssotpVuGLG1z079/fNNML2dOclmGcTlLq0CYLIWnj77PPPqY9q8xLG81yL7kvpuSsWbOmym2K7HjpUSNGjDB9wAEHmL766qtNs5/7gw8+aLpZs2ammWoXQtJu7d27t2k2+Nl+++1NX3HFFblPoAhkeQd5eJUJQ0imGk+ePDl1mSy2c65GPRthqjVDMLlCBvlWFq2NMedV6WvXrp3pnj17mqZdzndvHE7mO5774HVjGLlHjx6m3333XdNMH+X+tttuu9TzadKkSep+99tvP9MtW7ZMXTcEv5orQx38W3bTTTe52/KQQyCEEEIIfRAIIYQQosRCBlmyCQhtJNo9RxxxhOmPPvrINMMHtG+oOROUlhCt0Hh/b731lmnaotwf+5uXA7msySyNNTyyzGbm9nfeeefU7XAWcS6rVvjwmrPBSuvWrU2vXLnSNCvg0dp88sknTXN2dvzMf/HFF6ZXrFiRehy891ns8UKT7zuI5LL8GcYcPHhw3utvhMfnNdrhPejVq5fpe+65J3X5UsW7FwwB8Bq8/fbbpvnejzO8aNGTOXPmmGZYlH8fuG+GxJhxwL8bzCjh34ZXXnnFNN9lDD+HkMwY2bBhQ+o6PKaaZrPJIRBCCCGEPgiEEEIIUWIhA5Jvc6O+ffua5ixP2pa0eGh5epkBtEhZ1CiE5Iz3PfbYwzRtoTfffNM0LSUW0yhHdt11V9NeCKAmzTdoG3MGLSkHy7NUyJKRMWrUKNMs1kI7kk2neH9feukl07Rw4+IwHE+0dFl8hcfK4i11TU1n1S9fvtw03x012Yc3Bl588UXTAwYMyGubdU2WZ5XPFd/pfG5zFXniv3EdNohq1aqVaYYMaPVzXR4T9aeffpr6O8cVx0J8Tzme+HeN44/b4jItWrQI+SKHQAghhBD6IBBCCCFEAUIGnsVTncIxWbIJuMxxxx1nmr0JWBv6k08+MU07hgVQWGyCFg+tpj333DNxTLSLaFvRFuIMeR5TXcyezpdcln+XLl1MZ7nP3jLU3v442zfr8dUHvKIsWfGKppCRI0ea5rNKC5PPc1yrP21djpm4QAvHDM+JmnYui848++yzqfsuNCxCc9ppp5lmVhHfKTx2ZlGEkLyHPC8WjGG4hNfaK9rlhWRY3InhTRZXY5ZBbCfz3chzXb9+vWmOYxZaqm34HPK4eT14X+Iia3xGL7zwQtPnn3++6caNG5t+6KGHTHNc0aqP733acTD0cPvtt6ceTzxmrrnmGtN8hnhOHFfMhvvlL3+Zeky5kEMghBBCCH0QCCGEEKIAIYMsrW09YlvMs0YZDmANdc7W//jjj03TTmHBFdpAtGnYIpRZAoQhhhCS1g73zSJFtF5pt5XDDPlcNjVn4NI280IhWUIksa23kbZt26b+Xh/7F2TJ0ojHjBem88IEtEiPPPJI06xz77V4pV3KYlCe/R/fIz73DDMwm4BZQd27d089h2LC7CNmuLD+/eeff26amRO8ViEkrxdDAz/5yU9Mc2Y7t0v7m9vle4hjj8fK5bl9FpyKZ97ThvdsboZW65ILLrjA9MyZM03zHPh8xu9uZpUNHz7cNMcM7x3DMcwo43Xi8oT3Yvz48aZZBInvvlyFhThOuBxD1jzW2267zfSvfvUrd7tEDoEQQggh9EEghBBCiDxCBvnOJvd+p+UZt6Uk7EdAS582PC0iWpC03ri/1atXp+6Lthi3T+s0rsv+3HPPmZ4xY4ZphjFo8XBbXn3+uiZrZohnPXp16LNorksb1gsZeMdd1bGXI7QU45ABr7933kOGDDF9zjnnmF64cKFp2qq0Qrk/atr/XlghzkrgTGyOJ54DeydUVFSYZlGkYkLLlbYziwnRruW7Jj5GLwzGLAX2TuHyfFd5oVG+P5lZwOPjPePvcUhqyZIlppnZw3vLHgnFwnuGf/Ob35g+6KCDTD/11FOmvUJW8ZhhOMYL03DmPsMEfDdlyYrzsn0YtiDxM8NQlVe0i9eMz2AcKsmCHAIhhBBC6INACCGEEHmEDLIUHcqSceC1LA4hhN69e5tmISCuQ7uddhaXYQYALR7aLyzYweIbtOFoG8XhBtpLrO3P9WkHNmrUyPTBBx8cSpGsIQOvXXRNWsd6M+zZQjrLurmOo1Tgs8Njj2d+b4T2fK4MlUMOOcT0rbfeanrfffc1PW/evNTj4Exltlzl/riMNyud5xC3peZ/c33eLy/c17Fjx1Ab8F3ADCXOZqddy3dQ/D7jtWaIhNkd3B/fW7SpuQxDmrT2WfiMmQVcnscXF8Dhtmht8z5VVlaGuuK8884zzTbHXgEvL+wVQtJK5/PthbO9dsseXoEkZpp44yfOVOHx8V3B54njh/tWyEAIIYQQ1UIfBEIIIYSoXmEiz5LljEpaF5xhTyuM2QMhJK04Wl0MH8RW10ZoZ3qWHtd9/fXXTXP2M8MKueC2aM0wRMFj4j5KtTBR1h4LbOsc26Rp28pSl5/PC69PlmIopdobwrMXc2XXVEXcUnjo0KGmaavyHnEGOYtz8TrTZmYIjPYxw0M8Dj7bPLf4OWfYzKtHz2vG7WYJHRUChgb5DuJ14Hj37NoQkteRRZZYlIbvC9rAzCbgjHRuk8897zGtaYaReI95L+Nt8VrzfjADozbo16+faR7fhAkTTDPUwQwVvnPibBcvtED4d8PLnvLC6MQ7Dq7Laxz/beXfVC7HMcNlGLLz+sDkQg6BEEIIIfRBIIQQQohqhgxo4fft29e0V4eZmQG0PWhhhZCcYczQAq242JbbiDfTmQU7Vq1aZZr2HGfNc/u07bxQRQjJbARaR7RPaQWxIEwpkdV6p53G88q3MJEHt0mbzSvyUaohAy80xBnh3bp1M925c2fTXutsWv4hJENc48aNM83rRuvQu18cP7SxaT/zOjNLh2OMYy+2YxnK86xa7oPWvJeBUWgYSuQzxvAFz8MLF4YQwvz5803zPvM95xWdYkYGi3MxRMf3J8OTfB+xtwq3GRda47/xPDZs2GDaK+xWLNhn4OGHHzY9duxY0xdddJFphsni2frEm63vhfi88GdNerd428xFltAr/+ZUJ8wmh0AIIYQQ+iAQQgghRB4hAxYG6dmzp2laUrRpaMXQdqJlGdf0p+1FC8srEkH7jDOCaenR5qJNw3r8tF0ZGshl69AqpNXkXYN33nnH9PLly0O5wWvtzZbN1yrzluc2eQ1Z053Xs1RDBnxm7rrrLtPt27c37WVp0CKnxcw6+CGE8MYbb5hmC1w+x7S7WXSI15nj6tNPP01dns82M4e8GfhxeI82J8cMxyuPmyGiWbNmhdqG+/eyCTjznu+vEJIFoV577TXTvB/MGvCK0DA0sHjx4tT9McSapQ12PJudY5rva76j48yEYkPL++abbzbNMDX/TvD55PnE7+4sdn2Wd4q3br7bzBUy8NbhufK54RhjqDErcgiEEEIIoQ8CIYQQQuQRMqCFedhhh5lmm2La8ywoQ1uNy8SzsGlVEdqLnPVMy6xVq1am2SuAFiQtFIYYvFnV3G9cF5oZCLRxmclAa5FhgtqaMV1IaOvyvGg116T9MfGW4f1jyKBUOe2000zT5qT1mqUviNfmO4Tkc8nQAovZ8Hnj+rSruQ/azPvvv7/p2BLfyIoVK1J1fH9pZzIsQfuT50N7nKGR2oI9BBiuYpiU4cbYnj/wwANN0/ZnmIj3hmPMK1bTsmVL03yOmNHATBS+z/h8xFlT3Dd7BfA9yRBKsejUqZNpFlti6KpZs2amef34DPP84kJgXqaaR5YeL/mGA/LNvIqX4zl4mUO831mRQyCEEEIIfRAIIYQQIo+QAetvn3TSSab79+9vulevXqaPOeYY017BjThEQOue1iGtYlp0tBpp182ePdv0jBkzTI8fP9700qVLQxrTpk0zncvKoeXJkAgLm7Ro0cJ0XE+7FMl1vl5WBS276thgVR0Hn524mMpGSrU3xGOPPWaarXD79OljmjOpmSXAWeN85uOsBM/G59jg9aSNyOJC/J327IsvvmiazzaLw7DV8oknnmg6HmO8l14xL54Pbfa4lXJtMH36dNNdu3Y1vWbNGtO0o3n/QkgeP+12r50132G8VrTzuTwLQnF88r3KMcMQUVxEide3adOmphctWmSa2RHFguGOV155JXUZPiPxeWyE76i44JBXgChLxlSWd41XQChLAaI4JOEdkxcmYCiB4Z6syCEQQgghhD4IhBBCCJFHyMCzQR555JFUTZiJwBmibM0ZQtJy4yx+zlyePHmy6ZkzZ5rmjOR8oRVDO4kzd+OZqrQDaZt7fRc4M7lU8epjh+AXJvJ6CmQpOuThbac2ZjkXCz5L1PkSXwNarMwgYJiB6zDLh7XfvQyfLEyaNMl0u3btTM+dOzexnNfel+OEoQRmStQFL7zwgmn2ImAbZ2YVxUWjuJzX4tnrkcJxwvcL3ztct2HDhqm/MyzE44vr3PPfGB5u06aN6drI7OG5evefzw6fec9Gj/saeEWm+I7nPWI4Jd9QqBcyyNrLwCvm5b1H+Xuufg4ecgiEEEIIoQ8CIYQQQuiDQAghhBAhjzkEueLLVTFlypRUPXLkyGpvs5Aw7sJKWZsaueL7rHiWBa+qlheDy1L90Iu3lmpzo2IQV8MrhbkpHMelMqYLAd9VfP45D4Opf/EYYTzca7zjxaqZasg0O+6Dy3MOAOf7cK4A09CYKh1Ccr4Dq6rWdlMpXvOKiorUZVhBcs899zTtxdvjNEOmKnI8eTF6bjdL2iHnymRJ0fbmFsTrU/M4uF2vKmlW5BAIIYQQQh8EQgghhMgjZCA2bWjXZ6m4lYV8UxDzDVsIUSgWLFhgmpZ8rmpwnu3M8BitX/7uWc1chtY0QxKencxKhbGNzvTJAw44wPTEiRNDbcLQx7Jly0y/9NJLpll9lu8ENpNipc84VZchG6/6IsOWrOLJ68SUTt5fr3ldltBp/HvW5dLYcccdq1wmRg6BEEIIIfRBIIQQQgiFDATIZUPRJvWqVtZkf15FL+rqzJoVIh9oJ3MWP63z8847zzSr5sXjh2OGFj2tY1r9/J3HQQvaa2STpQkOiZut8Vhp1U+dOjV1/dqA2RyseskwDbMg+H5g9gAb0YWQbATF68MQDJfh/vbff3/TXbp0Mc1qugxD8Dj4PGVtyMZ7z2fIu8c8blUqFEIIIUS10AeBEEIIIRQyENnwZkzTwvQastC64rqcycuZwNwOdTk3NxLlgTdDfPz48abPOuss0yyM06BBg8Q6fO49S5/7Y8GcLMtz/HgN2hga8LIbQkgWWKLFXttZBoRhgn322ce09z6htc8Z9ixkFEIyzMOiT7T3afszs4AhA+6Dv/Pa8vgYMuB95O98BkLwnwOeA7fF0M/YsWNNDxo0KGRBDoEQQggh9EEghBBCCIUMBMhlKbLQB2ey0o6jhUZ7n9uiFcf9sXY7rTv+TjuMbEq9DERx8Wblf/bZZ6Zp0bZu3dp0PJu9TZs2qdvKUhvfq3Xv2dFeZg7tdYYSmEkQQnIssjhQXbJu3TrTpdIj45FHHqnrQygqcgiEEEIIoQ8CIYQQQoSw2Q9ZCsoH2bLFIuPlz0mh7k3WgkN//vOfTZ966qmp68yePdt0kyZNTDdt2tT0mjVrTDNMwJnbrBfer1+/1N/j8y/ENS3EdjRmikNdjxla73yeOes/hGRLYdbc5zjzsgYYHmOIjmEJFtJhrxFuk3X4uf0NGzYkjpX/vXjx4lBdNGZKk6z3RQ6BEEIIIfRBIIQQQog8QgZCCCGEqL/IIRBCCCGEPgiEEEIIoQ8CIYQQQgR9EAghhBAi6INACCGEEEEfBEIIIYQI+iAQQgghRNAHgRBCCCGCPgiEEEIIEUL4H6xNg742qYFIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "S9HlmZSv2Zgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the data (28x28 -> 784)\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "\n",
        "# Define different network structures\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, structure, activation):\n",
        "        super(MLP, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(len(structure)-1):\n",
        "            layers.append(nn.Linear(structure[i], structure[i+1]))\n",
        "            if i < len(structure)-2:\n",
        "                if activation == 'relu':\n",
        "                    layers.append(nn.ReLU())\n",
        "                elif activation == 'tanh':\n",
        "                    layers.append(nn.Tanh())\n",
        "                elif activation == 'sigmoid':\n",
        "                    layers.append(nn.Sigmoid())\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten the input\n",
        "        return self.model(x)\n",
        "\n",
        "def train_and_evaluate(model, trainloader, testloader, epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_accuracy = 100 * correct / total\n",
        "\n",
        "        # Testing accuracy\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        test_accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%')\n",
        "\n",
        "# Different network structures to try\n",
        "structures = [\n",
        "    [784, 128, 10],\n",
        "    [784, 256, 128, 10],\n",
        "    [784, 512, 256, 128, 10],\n",
        "    [784, 128, 64, 32, 10],\n",
        "    [784, 1024, 512, 10]\n",
        "]\n",
        "\n",
        "print(\"Testing different network structures with ReLU activation:\")\n",
        "for structure in structures:\n",
        "    print(f\"\\nStructure: {structure}\")\n",
        "    model = MLP(structure, 'relu')\n",
        "    train_and_evaluate(model, trainloader, testloader)\n",
        "\n",
        "# Test different activations on best structure\n",
        "best_structure = [784, 512, 256, 128, 10]  # Replace with your best structure\n",
        "activations = ['relu', 'tanh', 'sigmoid']\n",
        "\n",
        "print(\"\\nTesting different activation functions on best structure:\")\n",
        "for activation in activations:\n",
        "    print(f\"\\nActivation: {activation}\")\n",
        "    model = MLP(best_structure, activation)\n",
        "    train_and_evaluate(model, trainloader, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIzqOL8P2dOA",
        "outputId": "93ea6ce7-99c8-4f24-b875-ec1239d35d67"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing different network structures with ReLU activation:\n",
            "\n",
            "Structure: [784, 128, 10]\n",
            "Epoch 1: Train Acc: 82.46%, Test Acc: 84.47%\n",
            "Epoch 2: Train Acc: 86.24%, Test Acc: 85.89%\n",
            "Epoch 3: Train Acc: 87.68%, Test Acc: 86.58%\n",
            "Epoch 4: Train Acc: 88.37%, Test Acc: 86.75%\n",
            "Epoch 5: Train Acc: 89.05%, Test Acc: 87.39%\n",
            "Epoch 6: Train Acc: 89.50%, Test Acc: 87.39%\n",
            "Epoch 7: Train Acc: 89.96%, Test Acc: 86.94%\n",
            "Epoch 8: Train Acc: 90.39%, Test Acc: 87.84%\n",
            "Epoch 9: Train Acc: 90.57%, Test Acc: 87.70%\n",
            "Epoch 10: Train Acc: 91.02%, Test Acc: 87.91%\n",
            "\n",
            "Structure: [784, 256, 128, 10]\n",
            "Epoch 1: Train Acc: 82.15%, Test Acc: 85.48%\n",
            "Epoch 2: Train Acc: 86.26%, Test Acc: 85.59%\n",
            "Epoch 3: Train Acc: 88.01%, Test Acc: 86.66%\n",
            "Epoch 4: Train Acc: 88.64%, Test Acc: 87.10%\n",
            "Epoch 5: Train Acc: 89.31%, Test Acc: 87.59%\n",
            "Epoch 6: Train Acc: 89.76%, Test Acc: 87.36%\n",
            "Epoch 7: Train Acc: 90.19%, Test Acc: 87.39%\n",
            "Epoch 8: Train Acc: 90.65%, Test Acc: 87.05%\n",
            "Epoch 9: Train Acc: 91.08%, Test Acc: 88.29%\n",
            "Epoch 10: Train Acc: 91.31%, Test Acc: 88.03%\n",
            "\n",
            "Structure: [784, 512, 256, 128, 10]\n",
            "Epoch 1: Train Acc: 81.81%, Test Acc: 84.20%\n",
            "Epoch 2: Train Acc: 86.11%, Test Acc: 85.15%\n",
            "Epoch 3: Train Acc: 87.77%, Test Acc: 85.94%\n",
            "Epoch 4: Train Acc: 88.49%, Test Acc: 85.72%\n",
            "Epoch 5: Train Acc: 89.19%, Test Acc: 87.23%\n",
            "Epoch 6: Train Acc: 89.86%, Test Acc: 87.25%\n",
            "Epoch 7: Train Acc: 90.21%, Test Acc: 88.21%\n",
            "Epoch 8: Train Acc: 90.73%, Test Acc: 88.10%\n",
            "Epoch 9: Train Acc: 91.01%, Test Acc: 87.73%\n",
            "Epoch 10: Train Acc: 91.45%, Test Acc: 88.17%\n",
            "\n",
            "Structure: [784, 128, 64, 32, 10]\n",
            "Epoch 1: Train Acc: 80.83%, Test Acc: 83.90%\n",
            "Epoch 2: Train Acc: 85.79%, Test Acc: 85.51%\n",
            "Epoch 3: Train Acc: 87.08%, Test Acc: 85.33%\n",
            "Epoch 4: Train Acc: 88.02%, Test Acc: 87.15%\n",
            "Epoch 5: Train Acc: 88.75%, Test Acc: 86.62%\n",
            "Epoch 6: Train Acc: 89.24%, Test Acc: 87.60%\n",
            "Epoch 7: Train Acc: 89.89%, Test Acc: 87.77%\n",
            "Epoch 8: Train Acc: 90.12%, Test Acc: 87.42%\n",
            "Epoch 9: Train Acc: 90.39%, Test Acc: 87.73%\n",
            "Epoch 10: Train Acc: 90.85%, Test Acc: 87.68%\n",
            "\n",
            "Structure: [784, 1024, 512, 10]\n",
            "Epoch 1: Train Acc: 82.24%, Test Acc: 84.67%\n",
            "Epoch 2: Train Acc: 86.24%, Test Acc: 85.58%\n",
            "Epoch 3: Train Acc: 87.77%, Test Acc: 86.76%\n",
            "Epoch 4: Train Acc: 88.62%, Test Acc: 86.21%\n",
            "Epoch 5: Train Acc: 89.38%, Test Acc: 87.55%\n",
            "Epoch 6: Train Acc: 89.92%, Test Acc: 87.76%\n",
            "Epoch 7: Train Acc: 90.31%, Test Acc: 87.91%\n",
            "Epoch 8: Train Acc: 90.95%, Test Acc: 87.97%\n",
            "Epoch 9: Train Acc: 91.21%, Test Acc: 87.73%\n",
            "Epoch 10: Train Acc: 91.66%, Test Acc: 88.59%\n",
            "\n",
            "Testing different activation functions on best structure:\n",
            "\n",
            "Activation: relu\n",
            "Epoch 1: Train Acc: 81.84%, Test Acc: 84.37%\n",
            "Epoch 2: Train Acc: 85.98%, Test Acc: 85.50%\n",
            "Epoch 3: Train Acc: 87.53%, Test Acc: 86.79%\n",
            "Epoch 4: Train Acc: 88.45%, Test Acc: 86.98%\n",
            "Epoch 5: Train Acc: 89.23%, Test Acc: 87.08%\n",
            "Epoch 6: Train Acc: 89.70%, Test Acc: 86.73%\n",
            "Epoch 7: Train Acc: 90.44%, Test Acc: 87.99%\n",
            "Epoch 8: Train Acc: 90.58%, Test Acc: 87.68%\n",
            "Epoch 9: Train Acc: 91.13%, Test Acc: 88.66%\n",
            "Epoch 10: Train Acc: 91.43%, Test Acc: 88.57%\n",
            "\n",
            "Activation: tanh\n",
            "Epoch 1: Train Acc: 81.22%, Test Acc: 83.35%\n",
            "Epoch 2: Train Acc: 84.90%, Test Acc: 84.41%\n",
            "Epoch 3: Train Acc: 85.70%, Test Acc: 84.22%\n",
            "Epoch 4: Train Acc: 86.24%, Test Acc: 84.85%\n",
            "Epoch 5: Train Acc: 86.59%, Test Acc: 86.26%\n",
            "Epoch 6: Train Acc: 87.11%, Test Acc: 84.80%\n",
            "Epoch 7: Train Acc: 87.14%, Test Acc: 85.40%\n",
            "Epoch 8: Train Acc: 87.34%, Test Acc: 85.63%\n",
            "Epoch 9: Train Acc: 87.34%, Test Acc: 84.12%\n",
            "Epoch 10: Train Acc: 87.45%, Test Acc: 85.59%\n",
            "\n",
            "Activation: sigmoid\n",
            "Epoch 1: Train Acc: 75.71%, Test Acc: 82.74%\n",
            "Epoch 2: Train Acc: 85.43%, Test Acc: 84.62%\n",
            "Epoch 3: Train Acc: 87.11%, Test Acc: 86.23%\n",
            "Epoch 4: Train Acc: 87.92%, Test Acc: 86.69%\n",
            "Epoch 5: Train Acc: 88.71%, Test Acc: 87.20%\n",
            "Epoch 6: Train Acc: 89.23%, Test Acc: 85.49%\n",
            "Epoch 7: Train Acc: 89.72%, Test Acc: 86.96%\n",
            "Epoch 8: Train Acc: 90.10%, Test Acc: 87.33%\n",
            "Epoch 9: Train Acc: 90.45%, Test Acc: 87.51%\n",
            "Epoch 10: Train Acc: 90.88%, Test Acc: 87.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3"
      ],
      "metadata": {
        "id": "YILicQ1dF4tR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation a-e and some Experimentation"
      ],
      "metadata": {
        "id": "fTVlLXjh4UCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Implementation a-e: Baseline CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, dropout_rate=0, num_conv_layers=1):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Implementation a: First conv layer\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "\n",
        "        # Implementation b: First maxpool\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Experimentation c: Optional second conv layer\n",
        "        self.num_conv_layers = num_conv_layers\n",
        "        if num_conv_layers > 1:\n",
        "            self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "\n",
        "        # Calculate flattened size\n",
        "        self.flat_size = 32 * 13 * 13 if num_conv_layers == 1 else 64 * 5 * 5\n",
        "\n",
        "        # Experimentation b: Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Implementation d: Dense layer with ReLU\n",
        "        self.fc1 = nn.Linear(self.flat_size, 100)\n",
        "\n",
        "        # Implementation e: Output layer\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "\n",
        "        if self.num_conv_layers > 1:\n",
        "            x = self.pool(torch.relu(self.conv2(x)))\n",
        "\n",
        "        # Implementation c: Flatten layer\n",
        "        x = x.view(-1, self.flat_size)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_and_evaluate(model, trainloader, testloader, epochs, lr=0.01, store_metrics=False):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    train_acc_history = []\n",
        "    test_acc_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Testing\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "\n",
        "        if store_metrics:\n",
        "            train_acc_history.append(train_acc)\n",
        "            test_acc_history.append(test_acc)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0 or epoch == epochs-1:\n",
        "            print(f'Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
        "\n",
        "    if store_metrics:\n",
        "        return train_acc_history, test_acc_history\n",
        "    return test_acc"
      ],
      "metadata": {
        "id": "h6H1JZDS4hFu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(train_acc, test_acc, title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    epochs = range(10, len(train_acc) * 10 + 1, 10)\n",
        "    plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
        "    plt.plot(epochs, test_acc, 'r-', label='Validation Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{title}.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "ALqmmk5F4tgX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline training (10 epochs)\n",
        "print(\"Training baseline CNN for 10 epochs:\")\n",
        "model = CNN()\n",
        "test_acc = train_and_evaluate(model, trainloader, testloader, epochs=10)\n",
        "print(f\"Final test accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdI4v-V64v49",
        "outputId": "b561a9b2-3303-42d1-af99-89960cd67d87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training baseline CNN for 10 epochs:\n",
            "Epoch 10: Train Acc: 96.27%, Test Acc: 90.80%\n",
            "Final test accuracy: 90.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimentation a"
      ],
      "metadata": {
        "id": "_04pSoEuE7Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimentation a: 50 epochs baseline\n",
        "print(\"\\nTraining CNN for 50 epochs:\")\n",
        "model = CNN()\n",
        "train_acc, test_acc = train_and_evaluate(model, trainloader, testloader, epochs=50, store_metrics=True)\n",
        "plot_accuracies(train_acc[::10], test_acc[::10], \"Baseline CNN Performance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o0SB7IdZQCX",
        "outputId": "c8262d84-bf4b-4ecb-f350-c3d3a5e0232a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN for 50 epochs:\n",
            "Epoch 10: Train Acc: 96.32%, Test Acc: 91.15%\n",
            "Epoch 20: Train Acc: 98.71%, Test Acc: 90.26%\n",
            "Epoch 30: Train Acc: 99.50%, Test Acc: 90.92%\n",
            "Epoch 40: Train Acc: 100.00%, Test Acc: 91.76%\n",
            "Epoch 50: Train Acc: 100.00%, Test Acc: 91.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimentation b"
      ],
      "metadata": {
        "id": "k-NkiH8wH9P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimentation b: 50 epochs with dropout\n",
        "print(\"\\nTraining CNN for 50 epochs with dropout:\")\n",
        "model = CNN(dropout_rate=0.5)\n",
        "train_acc, test_acc = train_and_evaluate(model, trainloader, testloader, epochs=50, store_metrics=True)\n",
        "plot_accuracies(train_acc[::10], test_acc[::10], \"CNN Performance with Dropout\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBV8emZ8H_SM",
        "outputId": "782f8cfb-0b84-4076-9905-9f0601ac1c82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN for 50 epochs with dropout:\n",
            "Epoch 10: Train Acc: 92.78%, Test Acc: 91.29%\n",
            "Epoch 20: Train Acc: 94.81%, Test Acc: 91.22%\n",
            "Epoch 30: Train Acc: 95.79%, Test Acc: 91.72%\n",
            "Epoch 40: Train Acc: 96.21%, Test Acc: 91.63%\n",
            "Epoch 50: Train Acc: 96.72%, Test Acc: 91.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimentation c"
      ],
      "metadata": {
        "id": "Hi2jO7HkU6JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimentation c: Two conv layers\n",
        "print(\"\\nTraining CNN with two conv layers:\")\n",
        "model = CNN(dropout_rate=0.5, num_conv_layers=2)\n",
        "test_acc = train_and_evaluate(model, trainloader, testloader, epochs=10)\n",
        "print(f\"Final test accuracy with two conv layers: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6jwyqoXU8PU",
        "outputId": "e48ebe93-319d-447b-ec92-34bfb27dda88"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN with two conv layers:\n",
            "Epoch 10: Train Acc: 90.89%, Test Acc: 90.72%\n",
            "Final test accuracy with two conv layers: 90.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimentation d"
      ],
      "metadata": {
        "id": "opd72AZHYMML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimentation d: Different learning rates\n",
        "print(\"\\nTesting different learning rates:\")\n",
        "for lr in [0.001, 0.1]:\n",
        "    print(f\"\\nTraining with learning rate: {lr}\")\n",
        "    model = CNN(dropout_rate=0.5, num_conv_layers=2)\n",
        "    test_acc = train_and_evaluate(model, trainloader, testloader, epochs=10, lr=lr)\n",
        "    print(f\"Final test accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b8ECqO7YNuW",
        "outputId": "e0450a3f-03a8-4050-edfd-845a16984890"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing different learning rates:\n",
            "\n",
            "Training with learning rate: 0.001\n",
            "Epoch 10: Train Acc: 87.39%, Test Acc: 88.23%\n",
            "Final test accuracy: 88.23%\n",
            "\n",
            "Training with learning rate: 0.1\n",
            "Epoch 10: Train Acc: 9.90%, Test Acc: 10.00%\n",
            "Final test accuracy: 10.00%\n"
          ]
        }
      ]
    }
  ]
}